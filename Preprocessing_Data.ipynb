{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6b7e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d617ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>AScore</th>\n",
       "      <th>...</th>\n",
       "      <th>Legalh</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>VSA</th>\n",
       "      <th>illegal_score_sum</th>\n",
       "      <th>legal_score_sum</th>\n",
       "      <th>illegal_use</th>\n",
       "      <th>legal_use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>25-34</td>\n",
       "      <td>M</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>35-44</td>\n",
       "      <td>M</td>\n",
       "      <td>Professional certificate/ diploma</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>18-24</td>\n",
       "      <td>F</td>\n",
       "      <td>Masters degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>35-44</td>\n",
       "      <td>F</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>65+</td>\n",
       "      <td>F</td>\n",
       "      <td>Left school at 18 years</td>\n",
       "      <td>Canada</td>\n",
       "      <td>White</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>-0.30033</td>\n",
       "      <td>-1.55521</td>\n",
       "      <td>2.03972</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Age Gender                          Education Country Ethnicity  \\\n",
       "0   2  25-34      M                   Doctorate degree      UK     White   \n",
       "1   3  35-44      M  Professional certificate/ diploma      UK     White   \n",
       "2   4  18-24      F                     Masters degree      UK     White   \n",
       "3   5  35-44      F                   Doctorate degree      UK     White   \n",
       "4   6    65+      F            Left school at 18 years  Canada     White   \n",
       "\n",
       "    Nscore   Escore   Oscore   AScore  ...  Legalh  LSD  Meth  Mushrooms  \\\n",
       "0 -0.67825  1.93886  1.43533  0.76096  ...       0    0     1          0   \n",
       "1 -0.46725  0.80523 -0.84732 -1.62090  ...       0    0     0          0   \n",
       "2 -0.14882 -0.80615 -0.01928  0.59042  ...       0    0     0          0   \n",
       "3  0.73545 -1.63340 -0.45174 -0.30172  ...       0    0     0          0   \n",
       "4 -0.67825 -0.30033 -1.55521  2.03972  ...       0    0     0          0   \n",
       "\n",
       "   Nicotine  VSA  illegal_score_sum  legal_score_sum  illegal_use  legal_use  \n",
       "0         1    0                  3                4            1          1  \n",
       "1         0    0                  0                3            0          1  \n",
       "2         0    0                  1                3            1          1  \n",
       "3         0    0                  0                3            0          1  \n",
       "4         1    0                  0                3            0          1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Resources/cleaned_drug_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f492f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   1876\n",
       "Age                     6\n",
       "Gender                  2\n",
       "Education               9\n",
       "Country                 7\n",
       "Ethnicity               7\n",
       "Nscore                 49\n",
       "Escore                 42\n",
       "Oscore                 35\n",
       "AScore                 41\n",
       "Cscore                 41\n",
       "Impulsive              10\n",
       "SS                     11\n",
       "Alcohol                 2\n",
       "Amphet                  2\n",
       "Amyl                    2\n",
       "Benzos                  2\n",
       "Caff                    2\n",
       "Cannabis                2\n",
       "Choc                    2\n",
       "Coke                    2\n",
       "Crack                   2\n",
       "Ecstasy                 2\n",
       "Heroin                  2\n",
       "Ketamine                2\n",
       "Legalh                  2\n",
       "LSD                     2\n",
       "Meth                    2\n",
       "Mushrooms               2\n",
       "Nicotine                2\n",
       "VSA                     2\n",
       "illegal_score_sum      12\n",
       "legal_score_sum         6\n",
       "illegal_use             2\n",
       "legal_use               2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed891172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>AScore</th>\n",
       "      <th>Cscore</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>SS</th>\n",
       "      <th>illegal_use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-34</td>\n",
       "      <td>M</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35-44</td>\n",
       "      <td>M</td>\n",
       "      <td>Professional certificate/ diploma</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18-24</td>\n",
       "      <td>F</td>\n",
       "      <td>Masters degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35-44</td>\n",
       "      <td>F</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>White</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65+</td>\n",
       "      <td>F</td>\n",
       "      <td>Left school at 18 years</td>\n",
       "      <td>Canada</td>\n",
       "      <td>White</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>-0.30033</td>\n",
       "      <td>-1.55521</td>\n",
       "      <td>2.03972</td>\n",
       "      <td>1.63088</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.54858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>18-24</td>\n",
       "      <td>F</td>\n",
       "      <td>Some college or university, no certificate or ...</td>\n",
       "      <td>USA</td>\n",
       "      <td>White</td>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.92173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>18-24</td>\n",
       "      <td>M</td>\n",
       "      <td>Some college or university, no certificate or ...</td>\n",
       "      <td>USA</td>\n",
       "      <td>White</td>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.76540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>25-34</td>\n",
       "      <td>F</td>\n",
       "      <td>University degree</td>\n",
       "      <td>USA</td>\n",
       "      <td>White</td>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>-0.52593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>18-24</td>\n",
       "      <td>F</td>\n",
       "      <td>Some college or university, no certificate or ...</td>\n",
       "      <td>USA</td>\n",
       "      <td>White</td>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>18-24</td>\n",
       "      <td>M</td>\n",
       "      <td>Some college or university, no certificate or ...</td>\n",
       "      <td>Republic of Ireland</td>\n",
       "      <td>White</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1876 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age Gender                                          Education  \\\n",
       "0     25-34      M                                   Doctorate degree   \n",
       "1     35-44      M                  Professional certificate/ diploma   \n",
       "2     18-24      F                                     Masters degree   \n",
       "3     35-44      F                                   Doctorate degree   \n",
       "4       65+      F                            Left school at 18 years   \n",
       "...     ...    ...                                                ...   \n",
       "1871  18-24      F  Some college or university, no certificate or ...   \n",
       "1872  18-24      M  Some college or university, no certificate or ...   \n",
       "1873  25-34      F                                  University degree   \n",
       "1874  18-24      F  Some college or university, no certificate or ...   \n",
       "1875  18-24      M  Some college or university, no certificate or ...   \n",
       "\n",
       "                  Country Ethnicity   Nscore   Escore   Oscore   AScore  \\\n",
       "0                      UK     White -0.67825  1.93886  1.43533  0.76096   \n",
       "1                      UK     White -0.46725  0.80523 -0.84732 -1.62090   \n",
       "2                      UK     White -0.14882 -0.80615 -0.01928  0.59042   \n",
       "3                      UK     White  0.73545 -1.63340 -0.45174 -0.30172   \n",
       "4                  Canada     White -0.67825 -0.30033 -1.55521  2.03972   \n",
       "...                   ...       ...      ...      ...      ...      ...   \n",
       "1871                  USA     White -1.19430  1.74091  1.88511  0.76096   \n",
       "1872                  USA     White -0.24649  1.74091  0.58331  0.76096   \n",
       "1873                  USA     White  1.13281 -1.37639 -1.27553 -1.77200   \n",
       "1874                  USA     White  0.91093 -1.92173  0.29338 -1.62090   \n",
       "1875  Republic of Ireland     White -0.46725  2.12700  1.65653  1.11406   \n",
       "\n",
       "       Cscore  Impulsive       SS  illegal_use  \n",
       "0    -0.14277   -0.71126 -0.21575            1  \n",
       "1    -1.01450   -1.37983  0.40148            0  \n",
       "2     0.58489   -1.37983 -1.18084            1  \n",
       "3     1.30612   -0.21712 -0.21575            0  \n",
       "4     1.63088   -1.37983 -1.54858            0  \n",
       "...       ...        ...      ...          ...  \n",
       "1871 -1.13788    0.88113  1.92173            1  \n",
       "1872 -1.51840    0.88113  0.76540            1  \n",
       "1873 -1.38502    0.52975 -0.52593            1  \n",
       "1874 -2.57309    1.29221  1.22470            1  \n",
       "1875  0.41594    0.88113  1.22470            1  \n",
       "\n",
       "[1876 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns= ['VSA', 'Nicotine','Mushrooms','Meth','LSD','Legalh','Ketamine','Heroin','Ecstasy','Crack','Coke','Choc','Cannabis','Caff','illegal_score_sum','legal_score_sum','legal_use','Amyl','Amphet','Alcohol', 'ID','Benzos'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df04a472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>AScore</th>\n",
       "      <th>Cscore</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>SS</th>\n",
       "      <th>illegal_use</th>\n",
       "      <th>Age_18-24</th>\n",
       "      <th>Age_25-34</th>\n",
       "      <th>...</th>\n",
       "      <th>Country_Republic of Ireland</th>\n",
       "      <th>Country_UK</th>\n",
       "      <th>Country_USA</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Black</th>\n",
       "      <th>Ethnicity_Mixed-Black/Asian</th>\n",
       "      <th>Ethnicity_Mixed-White/Asian</th>\n",
       "      <th>Ethnicity_Mixed-White/Black</th>\n",
       "      <th>Ethnicity_Other</th>\n",
       "      <th>Ethnicity_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.67825</td>\n",
       "      <td>-0.30033</td>\n",
       "      <td>-1.55521</td>\n",
       "      <td>2.03972</td>\n",
       "      <td>1.63088</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.54858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>-1.19430</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>1.88511</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.13788</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.92173</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>-0.24649</td>\n",
       "      <td>1.74091</td>\n",
       "      <td>0.58331</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-1.51840</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>0.76540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>1.13281</td>\n",
       "      <td>-1.37639</td>\n",
       "      <td>-1.27553</td>\n",
       "      <td>-1.77200</td>\n",
       "      <td>-1.38502</td>\n",
       "      <td>0.52975</td>\n",
       "      <td>-0.52593</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>0.91093</td>\n",
       "      <td>-1.92173</td>\n",
       "      <td>0.29338</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-2.57309</td>\n",
       "      <td>1.29221</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>-0.46725</td>\n",
       "      <td>2.12700</td>\n",
       "      <td>1.65653</td>\n",
       "      <td>1.11406</td>\n",
       "      <td>0.41594</td>\n",
       "      <td>0.88113</td>\n",
       "      <td>1.22470</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1876 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nscore   Escore   Oscore   AScore   Cscore  Impulsive       SS  \\\n",
       "0    -0.67825  1.93886  1.43533  0.76096 -0.14277   -0.71126 -0.21575   \n",
       "1    -0.46725  0.80523 -0.84732 -1.62090 -1.01450   -1.37983  0.40148   \n",
       "2    -0.14882 -0.80615 -0.01928  0.59042  0.58489   -1.37983 -1.18084   \n",
       "3     0.73545 -1.63340 -0.45174 -0.30172  1.30612   -0.21712 -0.21575   \n",
       "4    -0.67825 -0.30033 -1.55521  2.03972  1.63088   -1.37983 -1.54858   \n",
       "...       ...      ...      ...      ...      ...        ...      ...   \n",
       "1871 -1.19430  1.74091  1.88511  0.76096 -1.13788    0.88113  1.92173   \n",
       "1872 -0.24649  1.74091  0.58331  0.76096 -1.51840    0.88113  0.76540   \n",
       "1873  1.13281 -1.37639 -1.27553 -1.77200 -1.38502    0.52975 -0.52593   \n",
       "1874  0.91093 -1.92173  0.29338 -1.62090 -2.57309    1.29221  1.22470   \n",
       "1875 -0.46725  2.12700  1.65653  1.11406  0.41594    0.88113  1.22470   \n",
       "\n",
       "      illegal_use  Age_18-24  Age_25-34  ...  Country_Republic of Ireland  \\\n",
       "0               1          0          1  ...                            0   \n",
       "1               0          0          0  ...                            0   \n",
       "2               1          1          0  ...                            0   \n",
       "3               0          0          0  ...                            0   \n",
       "4               0          0          0  ...                            0   \n",
       "...           ...        ...        ...  ...                          ...   \n",
       "1871            1          1          0  ...                            0   \n",
       "1872            1          1          0  ...                            0   \n",
       "1873            1          0          1  ...                            0   \n",
       "1874            1          1          0  ...                            0   \n",
       "1875            1          1          0  ...                            1   \n",
       "\n",
       "      Country_UK  Country_USA  Ethnicity_Asian  Ethnicity_Black  \\\n",
       "0              1            0                0                0   \n",
       "1              1            0                0                0   \n",
       "2              1            0                0                0   \n",
       "3              1            0                0                0   \n",
       "4              0            0                0                0   \n",
       "...          ...          ...              ...              ...   \n",
       "1871           0            1                0                0   \n",
       "1872           0            1                0                0   \n",
       "1873           0            1                0                0   \n",
       "1874           0            1                0                0   \n",
       "1875           0            0                0                0   \n",
       "\n",
       "      Ethnicity_Mixed-Black/Asian  Ethnicity_Mixed-White/Asian  \\\n",
       "0                               0                            0   \n",
       "1                               0                            0   \n",
       "2                               0                            0   \n",
       "3                               0                            0   \n",
       "4                               0                            0   \n",
       "...                           ...                          ...   \n",
       "1871                            0                            0   \n",
       "1872                            0                            0   \n",
       "1873                            0                            0   \n",
       "1874                            0                            0   \n",
       "1875                            0                            0   \n",
       "\n",
       "      Ethnicity_Mixed-White/Black  Ethnicity_Other  Ethnicity_White  \n",
       "0                               0                0                1  \n",
       "1                               0                0                1  \n",
       "2                               0                0                1  \n",
       "3                               0                0                1  \n",
       "4                               0                0                1  \n",
       "...                           ...              ...              ...  \n",
       "1871                            0                0                1  \n",
       "1872                            0                0                1  \n",
       "1873                            0                0                1  \n",
       "1874                            0                0                1  \n",
       "1875                            0                0                1  \n",
       "\n",
       "[1876 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_data = pd.get_dummies(df)\n",
    "numerical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ed376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numerical_data.drop(columns=[\"illegal_use\"])\n",
    "Y = numerical_data[\"illegal_use\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a11132",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34171380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler() model and fit it to the training data\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab067bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data by using the X_scaler and y_scaler models\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b4ea2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.725\n",
      "k: 3, Train/Test Score: 0.856/0.780\n",
      "k: 5, Train/Test Score: 0.829/0.787\n",
      "k: 7, Train/Test Score: 0.821/0.778\n",
      "k: 9, Train/Test Score: 0.805/0.783\n",
      "k: 11, Train/Test Score: 0.798/0.780\n",
      "k: 13, Train/Test Score: 0.791/0.776\n",
      "k: 15, Train/Test Score: 0.787/0.785\n",
      "k: 17, Train/Test Score: 0.783/0.780\n",
      "k: 19, Train/Test Score: 0.779/0.787\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, Y_train)\n",
    "    train_score = knn.score(X_train_scaled, Y_train)\n",
    "    test_score = knn.score(X_test_scaled, Y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "944e6d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5 Test Acc: 0.787\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, Y_train)\n",
    "print('k=5 Test Acc: %.3f' % knn.score(X_test_scaled, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1793b541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 6)                 234       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 283\n",
      "Trainable params: 283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a Keras Sequential model and add more than one Dense hidden layer\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=6, activation=\"relu\", input_dim=38))\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=6, activation=\"relu\"))\n",
    "\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the Sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c04e7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "44/44 [==============================] - 1s 1ms/step - loss: 0.7056 - accuracy: 0.5060\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6070\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.6146 - accuracy: 0.6674\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.5816 - accuracy: 0.7114\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7420\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.7655\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7790\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7868\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.7939\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7982\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7974\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.8003\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.8024\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.8060\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.8045\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.8067\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8095\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.8081\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.8088\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4232 - accuracy: 0.8095\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4208 - accuracy: 0.8088\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8109\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8109\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4164 - accuracy: 0.8067\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8117\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4133 - accuracy: 0.8138\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.8102\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8152\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8124\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 962us/step - loss: 0.4087 - accuracy: 0.8131\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8102\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8131\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4066 - accuracy: 0.8131\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.8124\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8131\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8124\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8131\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8145\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8138\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4015 - accuracy: 0.8138\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4013 - accuracy: 0.8145\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8145\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8138\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8145\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3989 - accuracy: 0.8131\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3983 - accuracy: 0.8138\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8131\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3974 - accuracy: 0.8131\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8145\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3969 - accuracy: 0.8159\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3960 - accuracy: 0.8131\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8131\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.8138\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8145\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3942 - accuracy: 0.8138\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8166\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8152\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8159\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.8181\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3921 - accuracy: 0.8181\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8195\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8223\n",
      "Epoch 63/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3911 - accuracy: 0.8181\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3907 - accuracy: 0.8216\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8223\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8202\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.8230\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3889 - accuracy: 0.8244\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8237\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8266\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8266\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8266\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8266\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8273\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3860 - accuracy: 0.8266\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3856 - accuracy: 0.8273\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.8308\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3847 - accuracy: 0.8316\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.8301\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8323\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3835 - accuracy: 0.8308\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3832 - accuracy: 0.8351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3830 - accuracy: 0.8337\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3832 - accuracy: 0.8351\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8351\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3824 - accuracy: 0.8344\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3816 - accuracy: 0.8365\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.8358\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.8330\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3804 - accuracy: 0.8358\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3800 - accuracy: 0.8380\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8365\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.8365\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8380\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8372\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8394\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8380\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8387\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8408\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8401\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8408\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8429\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8429\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3761 - accuracy: 0.8394\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8401\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3754 - accuracy: 0.8408\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3748 - accuracy: 0.8394\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3748 - accuracy: 0.8394\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3740 - accuracy: 0.8408\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8408\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8415\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8408\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3742 - accuracy: 0.8436\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8387\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3724 - accuracy: 0.8408\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8408\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3720 - accuracy: 0.8394\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 0s 937us/step - loss: 0.3718 - accuracy: 0.8394\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 0s 862us/step - loss: 0.3714 - accuracy: 0.8415\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 0s 968us/step - loss: 0.3714 - accuracy: 0.8422\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8394\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 0s 852us/step - loss: 0.3712 - accuracy: 0.8408\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8394\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 0s 908us/step - loss: 0.3705 - accuracy: 0.8394\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 0s 926us/step - loss: 0.3710 - accuracy: 0.8380\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 0s 980us/step - loss: 0.3701 - accuracy: 0.8415\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8408\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 0s 871us/step - loss: 0.3697 - accuracy: 0.8387\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 0s 919us/step - loss: 0.3690 - accuracy: 0.8372\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8401\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 0s 935us/step - loss: 0.3687 - accuracy: 0.8394\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 0s 869us/step - loss: 0.3687 - accuracy: 0.8394\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8401\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8387\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 0s 923us/step - loss: 0.3680 - accuracy: 0.8401\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 0s 951us/step - loss: 0.3676 - accuracy: 0.8422\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8394\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8422\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 0s 961us/step - loss: 0.3670 - accuracy: 0.8401\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3668 - accuracy: 0.8401\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8394\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3669 - accuracy: 0.8422\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.8394\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8401\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8394\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8443\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8422\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8429\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8408\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8429\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8415\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8436\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8415\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8422\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8422\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8429\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8436\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8436\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8429\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8422\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8429\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8408\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8436\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8408\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8436\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8429\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8415\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8429\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8429\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8422\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8408\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8443\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8415\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8429\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8443\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8443\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8422\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8451\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8429\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8458\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8472\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8479\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8472\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8458\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8458\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8451\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8465\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8465\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8451\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3570 - accuracy: 0.8465\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3558 - accuracy: 0.8472\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8486\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8486\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8479\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8465\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8479\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8465\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8479\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8486\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8472\n"
     ]
    }
   ],
   "source": [
    "# Compile the model and train over more than 100 epochs\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn_model.fit(X_train_scaled, Y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee836a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s - loss: 0.5072 - accuracy: 0.7846 - 185ms/epoch - 12ms/step\n",
      "Loss: 0.5071967840194702, Accuracy: 0.7846481800079346\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of model using the loss and predictive accuracy of the model on the test dataset.\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,Y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
