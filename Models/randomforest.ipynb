{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27d6244",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ced573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3d9410",
   "metadata": {},
   "source": [
    "# Data Review and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee86a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../Resources/cleaned_drug_data.csv\"\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb45f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45074efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"ID\", 'Alcohol',\n",
    "       'Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack',\n",
    "       'Ecstasy', 'Heroin', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms',\n",
    "       'Nicotine', 'VSA', 'illegal_score_sum', 'legal_score_sum', 'legal_use' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037497b0",
   "metadata": {},
   "source": [
    "Note: There are 6 categories for Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Education.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903662a5",
   "metadata": {},
   "source": [
    "Note: There are 9 categories for Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e76a08",
   "metadata": {},
   "source": [
    "Note: There are 7 categories for Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b133f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Ethnicity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffcb193",
   "metadata": {},
   "source": [
    "Note: There are 7 categories for Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9154be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884e0a5b",
   "metadata": {},
   "source": [
    "## Encoding Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of dtypes to help determine unique values\n",
    "df_cat=df.dtypes[df.dtypes == \"object\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f4a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display number of unique values\n",
    "df[df_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be361448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import onehotencoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df[df_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names_out(df_cat)\n",
    "encode_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810068d",
   "metadata": {},
   "source": [
    "## Merge to Create One Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge original df and encoded and then drop the categorical columns to leave only numerical columns\n",
    "df_merge = df.merge(encode_df, left_index=True, right_index=True)\n",
    "df_merge = df_merge.drop(df_cat, axis='columns')\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8dae31",
   "metadata": {},
   "source": [
    "## Split Data into Target and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5926ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for variable X\n",
    "df_pre = df_merge.drop(\"illegal_use\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d93a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X = df_pre\n",
    "y = df[\"illegal_use\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963dd7e5",
   "metadata": {},
   "source": [
    "## Train Test Split and Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4216e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202ee1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7523ea5",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=1, n_estimators=100, max_depth=10).fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sorted(zip(X.columns, clf.feature_importances_), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(10,20)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26c009",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4124854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the logisticregression model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e110949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score the training and test models and print the scores\n",
    "print(f\"Training Data Score: {clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa077c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a confusion matrix for this sample\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels = clf.classes_)\n",
    "cm_plot = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = clf.classes_)\n",
    "\n",
    "cm_plot.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a71bd3e",
   "metadata": {},
   "source": [
    "## Remove Ethnicity Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['Ethnicity'], axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of dtypes to help determine unique values\n",
    "df1_cat=df1.dtypes[df1.dtypes == \"object\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e536c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df1 = pd.DataFrame(enc.fit_transform(df1[df1_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df1.columns = enc.get_feature_names_out(df1_cat)\n",
    "encode_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318de0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge original df and encoded and then drop the categorical columns to leave only numerical columns\n",
    "df1_merge = df1.merge(encode_df1, left_index=True, right_index=True)\n",
    "df1_merge = df1_merge.drop(df1_cat, axis='columns')\n",
    "df1_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dfa9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for variable X\n",
    "df1_pre = df1_merge.drop(\"illegal_use\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X = df1_pre\n",
    "y = df[\"illegal_use\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a90b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5719b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d79ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=1, n_estimators=100, max_depth=11).fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91498b4f",
   "metadata": {},
   "source": [
    "## Remove Ethnicity and Country Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c1cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(['Ethnicity', 'Country'], axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f4a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of dtypes to help determine unique values\n",
    "df2_cat=df2.dtypes[df2.dtypes == \"object\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df2 = pd.DataFrame(enc.fit_transform(df2[df2_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df2.columns = enc.get_feature_names_out(df2_cat)\n",
    "encode_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge original df and encoded and then drop the categorical columns to leave only numerical columns\n",
    "df2_merge = df2.merge(encode_df2, left_index=True, right_index=True)\n",
    "df2_merge = df2_merge.drop(df2_cat, axis='columns')\n",
    "df2_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for variable X\n",
    "df2_pre = df2_merge.drop(\"illegal_use\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X = df2_pre\n",
    "y = df[\"illegal_use\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754c3a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=1, n_estimators=100, max_depth=6).fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
